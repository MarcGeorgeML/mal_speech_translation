{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e9a709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is NOT available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU in use:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is NOT available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b73cf2",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4a04f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing google flan-t5-small for translation refinement\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# c2t model loading example\n",
    "import whisper_s2t\n",
    "\n",
    "#preprocessing audio\n",
    "import importlib\n",
    "import overlap_split_and_preprocess\n",
    "importlib.reload(overlap_split_and_preprocess)\n",
    "from overlap_split_and_preprocess import split_preprocess_and_save_chunks\n",
    "import librosa\n",
    "\n",
    "# importing post processing model\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e037b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b08d3",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f34b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ffmpeg' is not built with soxr resampler, using 'swr' resampler. This may degrade performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\mals2t\\lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04d4b01c22449f9b5a2fec9391e9e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\mals2t\\lib\\site-packages\\whisper_s2t\\speech_segmenter\\frame_vad.py:74: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n",
      "e:\\anaconda3\\envs\\mals2t\\lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "custom_asr_options = {\n",
    "    # \"max_new_tokens\": 448,\n",
    "    \"num_beams\": 5,\n",
    "    \"condition_on_prev_tokens\": True,\n",
    "    \"compression_ratio_threshold\": 1.3,\n",
    "    \"temperature\": (0.0, 0.2, 0.4),\n",
    "    \"logprob_threshold\": -0.8,\n",
    "    \"no_speech_threshold\": 0.35,\n",
    "    \"return_timestamps\": True,\n",
    "}\n",
    "\n",
    "ct2_model = whisper_s2t.load_model(\n",
    "    model_identifier=\"large-v2\", \n",
    "    backend='CTranslate2', \n",
    "    compute_type='int8',  # Best for cpu\n",
    "    device=device,\n",
    "    asr_options=custom_asr_options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d2499",
   "metadata": {},
   "source": [
    "### Loading Post processing model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "797450e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the grammar correction model and tokenizer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrammarly/grammar-check\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m post_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      4\u001b[0m post_model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the grammar correction model and tokenizer\n",
    "model_name = \"grammarly/grammar-check\"\n",
    "post_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "post_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "post_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf9fc4",
   "metadata": {},
   "source": [
    "### Preprocessing and chunking audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7042cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated speech rate: 6.24 onsets/sec\n",
      "Speech rate is normal.\n",
      "Original length: 1438464, Processed length: 1438464\n",
      "RMS dB level: -16.39 dBFS\n",
      "Estimated speech rate: 5.90 onsets/sec\n",
      "Speech rate is normal.\n",
      "Original length: 1440000, Processed length: 1440000\n",
      "RMS dB level: -15.12 dBFS\n",
      "Estimated speech rate: 6.57 onsets/sec\n",
      "Speech rate is normal.\n",
      "Original length: 394752, Processed length: 394752\n",
      "RMS dB level: -14.48 dBFS\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "audio_path = \"megha.mp3\"\n",
    "audio, sr = librosa.load(audio_path, sr=None, mono=True)\n",
    "chunk_files = split_preprocess_and_save_chunks(audio,\n",
    "                                            sr, chunk_duration=30,\n",
    "                                            overlap_duration=5,\n",
    "                                            temp_dir=\"temp_chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e11ef",
   "metadata": {},
   "source": [
    "### Warmup Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29675329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 100/100 [00:38<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Warmup step: run a dummy transcription on a short audio file\n",
    "dummy_file = \"test_short.aac\"  # Path to a very short audio file (can be silence)\n",
    "dummy_results = ct2_model.transcribe_with_vad(\n",
    "    [dummy_file],\n",
    "    lang_codes=['ml'],\n",
    "    tasks=['translate'],\n",
    "    initial_prompts=[None],\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd0a22",
   "metadata": {},
   "source": [
    "### Translating main audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6929a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 300/300 [02:56<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# actual inference\n",
    "results = ct2_model.transcribe_with_vad(\n",
    "    chunk_files,\n",
    "    lang_codes=['ml'],\n",
    "    tasks=['translate'],\n",
    "    initial_prompts=[None],\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "# Each element in results is a list of segments for that audio file\n",
    "# Example: get all segments from all files\n",
    "all_segments = []\n",
    "for file_segments in results:\n",
    "    all_segments.extend(file_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e049b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Before the establishment of the IKKK, Kerala was divided into four parts. Thiruvidhamkore, Kochi, Malabar, South Kannada. The people of these villages were of the same culture, language and lifestyle. Kerala was formed by combining them. In 1920, the Nagpur Congress decided to form the committee of the organization in the language-based position. In 1921,', 'avg_logprob': -0.6828007055132577, 'no_speech_prob': 0.00013107861741445959, 'start_time': np.float64(1.38), 'end_time': 29.968}, {'text': 'The committee was formed in 1921 and the Congress Committee was established in 1928.', 'avg_logprob': -1.2479616867171393, 'no_speech_prob': 0.1292824149131775, 'start_time': np.float64(0.04), 'end_time': np.float64(18.98)}, {'text': 'The government has also announced that the government will provide the necessary funds for the construction of the Akhila Kerala Kudiyan Samayalam in 1928.', 'avg_logprob': -1.3518198889655035, 'no_speech_prob': 0.43902143836021423, 'start_time': np.float64(19.32), 'end_time': 30.0}, {'text': 'In 1928, Akhila Kerala Kudiyan Samayalam was inaugurated and the need for Kerala was met.', 'avg_logprob': -0.6136395425507517, 'no_speech_prob': 0.6618963479995728, 'start_time': 0.0, 'end_time': 8.224}]\n"
     ]
    }
   ],
   "source": [
    "print(all_segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59ca090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Before the establishment of the IKKK, Kerala was divided into four parts. Thiruvidhamkore, Kochi, Malabar, South Kannada. The people of these villages were of the same culture, language and lifestyle. Kerala was formed by combining them. In 1920, the Nagpur Congress decided to form the committee of the organization in the language-based position. In 1921,', 'The committee was formed in 1921 and the Congress Committee was established in 1928.', 'The government has also announced that the government will provide the necessary funds for the construction of the Akhila Kerala Kudiyan Samayalam in 1928.', 'In 1928, Akhila Kerala Kudiyan Samayalam was inaugurated and the need for Kerala was met.']\n"
     ]
    }
   ],
   "source": [
    "# Suppose segments is your list of segment dicts\n",
    "texts = [seg[\"text\"] for seg in all_segments if \"text\" in seg]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "491b38ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Before the establishment of the IKKK, Kerala was divided into four parts. Thiruvidhamkore, Kochi, Malabar, South Kannada. The people of these villages were of the same culture, language and lifestyle. Kerala was formed by combining them. In 1920, the Nagpur Congress decided to form the committee of the organization in the language-based position. In 1921,', 'The committee was formed in 1921 and the Congress Committee was established in 1928.', 'The government has also announced that the government will provide the necessary funds for the construction of the Akhila Kerala Kudiyan Samayalam in 1928.', 'In 1928, Akhila Kerala Kudiyan Samayalam was inaugurated and the need for Kerala was met.']\n"
     ]
    }
   ],
   "source": [
    "def remove_consecutive_duplicates_texts(texts):\n",
    "    cleaned = []\n",
    "    prev_text = None\n",
    "    for text in texts:\n",
    "        text = text.strip()\n",
    "        if text and text != prev_text:\n",
    "            cleaned.append(text)\n",
    "        prev_text = text\n",
    "    return cleaned\n",
    "\n",
    "cleaned_texts = remove_consecutive_duplicates_texts(texts)\n",
    "print(cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d7c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before the establishment of the IKKK, Kerala was divided into four parts. Thiruvidhamkore, Kochi, Malabar, South Kannada. The people of these villages were of the same culture, language and lifestyle. Kerala was formed by combining them. In 1920, the Nagpur Congress decided to form the committee of the organization in the language-based position. In 1921,The committee was formed in 1921 and the Congress Committee was established in 1928.The government has also announced that the government will provide the necessary funds for the construction of the Akhila Kerala Kudiyan Samayalam in 1928.In 1928, Akhila Kerala Kudiyan Samayalam was inaugurated and the need for Kerala was met.\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "def remove_fuzzy_duplicates_texts(texts, threshold=90):\n",
    "    \"\"\"\n",
    "    Removes texts that are very similar to the previous kept text.\n",
    "    threshold: similarity score (0-100), higher means stricter.\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    prev_text = \"\"\n",
    "    for text in texts:\n",
    "        t = text.strip()\n",
    "        if fuzz.ratio(t, prev_text) < threshold:\n",
    "            cleaned.append(t)\n",
    "            prev_text = t\n",
    "    return cleaned\n",
    "\n",
    "# Usage:\n",
    "fuzzy_cleaned_texts = remove_fuzzy_duplicates_texts(cleaned_texts, threshold=90)\n",
    "final_text = \"\".join(fuzzy_cleaned_texts)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f064abd",
   "metadata": {},
   "source": [
    "### Further refining translated text using another llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correct grammatical errors in a sentence\n",
    "def correct_grammar(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = post_tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Generate corrected text\n",
    "    with torch.no_grad():\n",
    "        outputs = post_model.generate(**inputs)\n",
    "    \n",
    "    # Decode the generated tokens back to text\n",
    "    corrected_text = post_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "\n",
    "# Correct the grammar\n",
    "corrected_text = correct_grammar(final_text)\n",
    "\n",
    "print(\"Original Text:\", final_text)\n",
    "print(\"Corrected Text:\", corrected_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mals2t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
